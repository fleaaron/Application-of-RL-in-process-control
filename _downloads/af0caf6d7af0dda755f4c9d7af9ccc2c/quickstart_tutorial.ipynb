{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gYWLbkMqd24A"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggd4lr93d24D"
      },
      "source": [
        "[Learn the Basics](intro.html) \\|\\| **Quickstart** \\|\\|\n",
        "[Tensors](tensorqs_tutorial.html) \\|\\| [Datasets &\n",
        "DataLoaders](data_tutorial.html) \\|\\|\n",
        "[Transforms](transforms_tutorial.html) \\|\\| [Build\n",
        "Model](buildmodel_tutorial.html) \\|\\|\n",
        "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
        "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
        "Model](saveloadrun_tutorial.html)\n",
        "\n",
        "Quickstart\n",
        "==========\n",
        "\n",
        "This section runs through the API for common tasks in machine learning.\n",
        "Refer to the links in each section to dive deeper.\n",
        "\n",
        "Working with data\n",
        "-----------------\n",
        "\n",
        "PyTorch has two [primitives to work with\n",
        "data](https://pytorch.org/docs/stable/data.html):\n",
        "`torch.utils.data.DataLoader` and `torch.utils.data.Dataset`. `Dataset`\n",
        "stores the samples and their corresponding labels, and `DataLoader`\n",
        "wraps an iterable around the `Dataset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "weQlF-nEd24E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIOENPRzd24F"
      },
      "source": [
        "PyTorch offers domain-specific libraries such as\n",
        "[TorchText](https://pytorch.org/text/stable/index.html),\n",
        "[TorchVision](https://pytorch.org/vision/stable/index.html), and\n",
        "[TorchAudio](https://pytorch.org/audio/stable/index.html), all of which\n",
        "include datasets. For this tutorial, we will be using a TorchVision\n",
        "dataset.\n",
        "\n",
        "The `torchvision.datasets` module contains `Dataset` objects for many\n",
        "real-world vision data like CIFAR, COCO ([full list\n",
        "here](https://pytorch.org/vision/stable/datasets.html)). In this\n",
        "tutorial, we use the FashionMNIST dataset. Every TorchVision `Dataset`\n",
        "includes two arguments: `transform` and `target_transform` to modify the\n",
        "samples and labels respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98berDFPd24F",
        "outputId": "3325feb6-06f5-4945-9cac-92dd212bd077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 22.0MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 341kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 6.32MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "\n",
        "plt.imshow(training_data.data[randint(0,len(training_data.data))], cmap = 'gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "2sZ8FgU4evld",
        "outputId": "b662cdd9-69d6-48f7-e4c8-5d1db1738c1b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e16b8d0ebd0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7-BwTtxd24G"
      },
      "source": [
        "We pass the `Dataset` as an argument to `DataLoader`. This wraps an\n",
        "iterable over our dataset, and supports automatic batching, sampling,\n",
        "shuffling and multiprocess data loading. Here we define a batch size of\n",
        "64, i.e. each element in the dataloader iterable will return a batch of\n",
        "64 features and labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYyBzMQ3d24G",
        "outputId": "45c04869-20c2-4e5b-dc13-709f412e9c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QNhGcrZd24G"
      },
      "source": [
        "Read more about [loading data in PyTorch](data_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-YSBJi-d24H"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUbX2rxNd24H"
      },
      "source": [
        "Creating Models\n",
        "===============\n",
        "\n",
        "To define a neural network in PyTorch, we create a class that inherits\n",
        "from\n",
        "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
        "We define the layers of the network in the `__init__` function and\n",
        "specify how data will pass through the network in the `forward`\n",
        "function. To accelerate operations in the neural network, we move it to\n",
        "the\n",
        "[accelerator](https://pytorch.org/docs/stable/torch.html#accelerators)\n",
        "such as CUDA, MPS, MTIA, or XPU. If the current accelerator is\n",
        "available, we will use it. Otherwise, we use the CPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHvcU-ZOd24H",
        "outputId": "0b2903e6-c494-4582-ab03-2e978a440e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.Tensor([[20,33, 43],\n",
        "                  [8, 97, 75],\n",
        "                  [12, 32, 86]])\n",
        "\n",
        "print(a)\n",
        "a = torch.flatten(a)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb0N5VbcgiGi",
        "outputId": "28992db3-e336-4e52-b4ef-aa81a2136d13"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[20., 33., 43.],\n",
            "        [ 8., 97., 75.],\n",
            "        [12., 32., 86.]])\n",
            "tensor([20., 33., 43.,  8., 97., 75., 12., 32., 86.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6n9OD1Nd24I"
      },
      "source": [
        "Read more about [building neural networks in\n",
        "PyTorch](buildmodel_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvgxANbXd24I"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzW3evCLd24I"
      },
      "source": [
        "Optimizing the Model Parameters\n",
        "===============================\n",
        "\n",
        "To train a model, we need a [loss\n",
        "function](https://pytorch.org/docs/stable/nn.html#loss-functions) and an\n",
        "[optimizer](https://pytorch.org/docs/stable/optim.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UuU3CFvSd24I"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZGTdyndd24I"
      },
      "source": [
        "In a single training loop, the model makes predictions on the training\n",
        "dataset (fed to it in batches), and backpropagates the prediction error\n",
        "to adjust the model\\'s parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,(j,k) in enumerate(train_dataloader):\n",
        "  print(i)\n",
        "  print(j)\n",
        "  print(len(j))\n",
        "  print(j.shape)\n",
        "  print(k)\n",
        "  break"
      ],
      "metadata": {
        "id": "GMmsjYYnHq4G",
        "outputId": "d25c1bf5-450d-4a0b-eb73-074f33b748e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
            "64\n",
            "torch.Size([64, 1, 28, 28])\n",
            "tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4, 3, 1, 4, 8,\n",
            "        4, 3, 0, 2, 4, 4, 5, 3, 6, 6, 0, 8, 5, 2, 1, 6, 6, 7, 9, 5, 9, 2, 7, 3,\n",
            "        0, 3, 3, 3, 7, 2, 2, 6, 6, 8, 3, 3, 5, 0, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "gwnK_De3d24I"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BORYiqD5d24I"
      },
      "source": [
        "We also check the model\\'s performance against the test dataset to\n",
        "ensure it is learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "WrDw0IfHd24J"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW2U8fz2d24J"
      },
      "source": [
        "The training process is conducted over several iterations (*epochs*).\n",
        "During each epoch, the model learns parameters to make better\n",
        "predictions. We print the model\\'s accuracy and loss at each epoch;\n",
        "we\\'d like to see the accuracy increase and the loss decrease with every\n",
        "epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYrfHYnFd24J",
        "outputId": "d11f5b9d-0f88-47c3-bdfe-0d081ca0bc66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.308756  [   64/60000]\n",
            "loss: 2.292352  [ 6464/60000]\n",
            "loss: 2.271163  [12864/60000]\n",
            "loss: 2.264385  [19264/60000]\n",
            "loss: 2.255493  [25664/60000]\n",
            "loss: 2.213098  [32064/60000]\n",
            "loss: 2.224258  [38464/60000]\n",
            "loss: 2.190428  [44864/60000]\n",
            "loss: 2.186670  [51264/60000]\n",
            "loss: 2.143380  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 37.9%, Avg loss: 2.148456 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.161453  [   64/60000]\n",
            "loss: 2.149386  [ 6464/60000]\n",
            "loss: 2.088535  [12864/60000]\n",
            "loss: 2.102829  [19264/60000]\n",
            "loss: 2.058458  [25664/60000]\n",
            "loss: 1.988473  [32064/60000]\n",
            "loss: 2.011582  [38464/60000]\n",
            "loss: 1.937898  [44864/60000]\n",
            "loss: 1.946540  [51264/60000]\n",
            "loss: 1.853906  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 58.2%, Avg loss: 1.867492 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.905983  [   64/60000]\n",
            "loss: 1.870661  [ 6464/60000]\n",
            "loss: 1.758341  [12864/60000]\n",
            "loss: 1.794599  [19264/60000]\n",
            "loss: 1.688924  [25664/60000]\n",
            "loss: 1.643400  [32064/60000]\n",
            "loss: 1.651596  [38464/60000]\n",
            "loss: 1.567944  [44864/60000]\n",
            "loss: 1.602190  [51264/60000]\n",
            "loss: 1.479356  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.4%, Avg loss: 1.508728 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.580119  [   64/60000]\n",
            "loss: 1.539413  [ 6464/60000]\n",
            "loss: 1.400239  [12864/60000]\n",
            "loss: 1.467849  [19264/60000]\n",
            "loss: 1.351213  [25664/60000]\n",
            "loss: 1.349507  [32064/60000]\n",
            "loss: 1.352474  [38464/60000]\n",
            "loss: 1.287716  [44864/60000]\n",
            "loss: 1.333832  [51264/60000]\n",
            "loss: 1.226429  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.5%, Avg loss: 1.252724 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.328926  [   64/60000]\n",
            "loss: 1.304809  [ 6464/60000]\n",
            "loss: 1.149471  [12864/60000]\n",
            "loss: 1.255673  [19264/60000]\n",
            "loss: 1.127631  [25664/60000]\n",
            "loss: 1.152150  [32064/60000]\n",
            "loss: 1.165534  [38464/60000]\n",
            "loss: 1.108564  [44864/60000]\n",
            "loss: 1.161948  [51264/60000]\n",
            "loss: 1.073422  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.9%, Avg loss: 1.090255 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu1gXAO3d24J"
      },
      "source": [
        "Read more about [Training your model](optimization_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKFapOhed24J"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m7z7URnd24J"
      },
      "source": [
        "Saving Models\n",
        "=============\n",
        "\n",
        "A common way to save a model is to serialize the internal state\n",
        "dictionary (containing the model parameters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry5-WBDpd24J",
        "outputId": "6762b870-c0e0-4880-da9d-f561fdfb30b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kbqz8jCd24J"
      },
      "source": [
        "Loading Models\n",
        "==============\n",
        "\n",
        "The process for loading a model includes re-creating the model structure\n",
        "and loading the state dictionary into it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrWKkDk-d24J",
        "outputId": "150aa055-9059-40f0-bee4-e5db69107e03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fM0d1AKd24K"
      },
      "source": [
        "This model can now be used to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRlRpSUQd24K",
        "outputId": "0d0060de-8dee-417d-bcc8-c8c70f1be25f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ],
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diwh8kDjd24K"
      },
      "source": [
        "Read more about [Saving & Loading your\n",
        "model](saveloadrun_tutorial.html).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}